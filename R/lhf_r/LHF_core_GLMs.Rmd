---
title: "LHF_core_GLMs"
author: "FiG-T"
data: "`r Sys.Date()`"
output: 
  html_document: 
    keep_md: yes
    toc: yes
toc: TRUE
editor_options:
  markdown:
    wrap: 80
  chunk_output_type: inline 
---

# Introduction

This markdown focuses on how to run the Generalised Linear Mixed Models (GLMs)
that make up the bulk of the core analysis.

## Libraries

```{r libraries}
library(feather)
library(dplyr)
library(tidyr)
library(lme4)
library(parallel)
library(ggplot2)
library(stringr)
```

```{r palettes}

source("https://raw.githubusercontent.com/FiG-T/scripts/main/R/lhf_r/colour_palettes.R")

```

# Required data

1.  Genotype matrix (see LHF_genetic_data_curation_pipeline.Rmd)
2.  Principal Component Scores
3.  Environmental metadata for all of the samples (in countries that meet the
    requirements)
4.  A list of all the mtDNA loci and their classifications

```{r load_required_data}

# genotype matrix
lhf_gt_t <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_gt_table_02_2024.feather"
)

# patristic distances -- DEPRICATED
#patr_dist_df <- feather::read_feather(
#  path = "~/Documents/data/lhf_d/feather/KC345983_patristic_distances_FastTree_02_2024.feather"
#)

# environemental metadata 
lhf_meta2 <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_meta2_maf0.005_data_11_2023.feather"
)

# mtDNA loci positioning 
mt_loci_pos <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/mtDNA_loci_positions_classifications.feather"
)

# mtDNA PCA scores 
lhf_pca_scores <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_pca_scores_0.005_03_2024.feather"
)
# mtDNA PCA eigenvalues
lhf_pca_eig <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_pca_eig_0.005_03_2024.feather"
)
```

## Patristic Distances Metafile

Filter countries to only keep individuals that come from a country with more
that 20 sequences.

```{r country_filter}
# group by country and summarise: 
country_N <- lhf_meta2 %>%  # generated above
  group_by(country) %>%
  summarise(
    N = n()
  )

# filter out countries with fewer than 20
country_N <- country_N %>%
  filter(N >= 20)  # define the cutoff value. 

# convert remaining countries to a list 
country_N <- c(country_N$country)

lhf_meta2 <- lhf_meta2 %>%
  filter(country %in% country_N)
```

# Merging datasets

The GLM models require all the data to be contained within a single table, it is
therefore necessary to join all the datasets together.

```{r merge_datasets}

# combine environmental data and patristic distances
lhf_gt_meta_pd <- dplyr::left_join(
  lhf_meta2, 
  patr_dist_df, 
  by = "samples"
)

# add in genotype data 
lhf_gt_meta_pd <- dplyr::left_join(
  lhf_gt_meta_pd, 
  lhf_gt_t, 
  by = join_by("samples" == "id")
)

# format column names 
names(lhf_gt_meta_pd) <- gsub(
  pattern = "1_", 
  replacement = "pos_", 
  x = names(lhf_gt_meta_pd)
)

# Convert genotype data to numeric 
for (x in 21:ncol(lhf_gt_meta_pd)){

col <- names(lhf_gt_meta_pd)[x]

lhf_gt_meta_pd[[col]] <- as.numeric(lhf_gt_meta_pd[[col]])
}
```

This combined contains data on:

1.  Unique sample codes for each mtDNA sequence.
2.  Associated geographical data
3.  Associated BioClimatic covariates (arranged by countries).
4.  The patristic distance between each individual and individual KC345983 (from
    Botswana)

As the range and units or the different environmental covariates are variable,
these all need to be scaled before being used in the GLM analysis.

```{r scale_covariates}

# Scale the values 
col_to_scale <- c(4,5,11:19)
for (x in col_to_scale){
  
  col <- names(lhf_gt_meta_pd)[x]
  
  lhf_gt_meta_pd[[col]] <- scale(lhf_gt_meta_pd[[col]])
}

```

```{r save_gt_meta_pd}

# Save this file 
feather::write_feather(
  x = lhf_gt_meta_pd, 
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pd_KC345983.feather"
)

```

## Adding PCs to metafile

```{r re_load_data}

# load in data 
lhf_gt_meta_pd <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pd_KC345983.feather"
)

# load in pca scores
lhf_pca_scores <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_pca_scores_0.005_03_2024.feather"
)

# load in metadata with acc for all indv in pca
lhf_meta2 <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_meta2_maf0.005_data_11_2023.feather"
)

```

```{r merge_PC_meta}

# check the number of rows in each 
nrow(lhf_gt_meta_pd) 
nrow(lhf_pca_scores)
nrow(lhf_meta2)

# lhf_meta2 matches the pca scores (this is as meta 2 was filtered to create gt_meta_pd) - see core_GLMs

# bind the acc numbers to the pca scores 
lhf_pca_scores <- cbind(
  lhf_meta2 %>% select(acc), 
  lhf_pca_scores
)

head(lhf_pca_scores)

# use this to combine with the full metadata table 
lhf_gt_meta_pc <- right_join(
  x = lhf_pca_scores, 
  y = lhf_gt_meta_pd, 
  by = "acc"
)

lhf_gt_meta_pc$PC1 <- scale(lhf_gt_meta_pc$PC1)
lhf_gt_meta_pc$PC2 <- scale(lhf_gt_meta_pc$PC2)
lhf_gt_meta_pc$PC3 <- scale(lhf_gt_meta_pc$PC3)
lhf_gt_meta_pc$PC4 <- scale(lhf_gt_meta_pc$PC4)

lhf_gt_meta_pc <- lhf_gt_meta_pc %>%
  select(-patr_KC345983)

head(lhf_gt_meta_pc)

nrow(lhf_gt_meta_pc)
  # this is the same length as before
```

Save this file:

```{r save_meta_pc}

# Save this file 
feather::write_feather(
  x = lhf_gt_meta_pc, 
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_PCs.feather"
)

```

## Down-sampling

As there are some countries that have a noticably larger number of individuals
(N\>1000) there is the possibility that these countries may create artefacts in
the downstream analysis.

One way to check that this is not the case is to sequenctially drop countries
with a large sample size, re-run the analysis, and check that the results are
stable. This is computationally expensive, but has been carried out as a sanity
check (see below [Dropping countries]).

An alternate method is to cap the maximum number of individuals from each
population, and down-sample countries to meet this cap. In this instance a cap
of 1000 individuals has been used.

```{r country_N}

N_cap <- 1000 # the cap in place

lhf_gt_meta_pc %>% 
  group_by(country) %>%
  summarise(
    N = n()
  ) %>%
   filter(N > N_cap) %>%
   print()
```

### Down-sampling data curation

```{r down_sample_curation}

countries_to_sample <- c("USA", "GBR", "ESP", "RUS") # use ISO3 codes (help avoid annoying errors)

down_sampler <- function(
        input, 
        N_cap, 
        sample_countries
) {
  
  # keep countries that do not need to be downsampled
  table_unedited <- input %>%
    filter(!iso3 %in% sample_countries) 
  
  message(
    " 'Unedited' samples preserved . 
    --------------------------------------------------"
  )
  
  table_sampled <- input %>%
    filter(iso3 %in% sample_countries) %>% # select countries to sample
    group_by(iso3) %>% # group by each country 
    slice_sample(
      n = N_cap,  # the cap you are downsampling to
      replace = FALSE # each indv can only be sampled once
    )
  
  # join the unsampled countries with the newly sampled individuals 
  table_combined <- rbind(table_unedited, table_sampled)
  
  return(table_combined)
  
}

lhf_gt_meta_pc_ds <- down_sampler(
  input = lhf_gt_meta_pc, 
  N_cap = 1000, 
  sample_countries = countries_to_sample
)

# check that the countries have been successfully downsampled
lhf_gt_meta_pc_ds %>% 
  group_by(country) %>%
  summarise(
    N = n()
  ) %>%
  slice_max(N, n = 10) %>%
  print()
```

Save this file too:

```{r save_downsampled}
feather::write_feather(
  x = lhf_gt_meta_pc_ds, 
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_PCs_DOWNSAMPLED.feather"
)

```

### Plotting PCs

I thought it was worth checking quickly how the PCs are distributed across the different axis.

```{r PC_correlations}

psych::pairs.panels(
  x = lhf_gt_meta_pc[,c(2:5)], 
  lm = TRUE, 
  stars = TRUE, 
  hist.col = "deepskyblue3"
)
```

# Running GLMs

This requires the combined dataset from above.

```{r load_glm_data}

# DOWNSAMPLED DATA ---- USE AS A FIRST PORT OF CALL
lhf_gt_meta_pc_ds <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_PCs_DOWNSAMPLED.feather"
)

# --- OR --- not downsampled
#lhf_gt_meta_pc <- feather::read_feather(
#  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_PCs.feather"
#)


# --- OR --- load in data with patristic distances
#lhf_gt_meta_pd <- feather::read_feather(
#  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pd_KC345983.feather"
#)


```

## Loading required functions

The following functions are required to run the GLM models.

The overall workflow is:

1.  Construct a null and full model for each SNP.
2.  Calculate the dispersion ratio for each full model.
3.  Filter out full models that are over or under-dispersed.
4.  Run a comparison between the null and full model.
5.  Select sites whereby the full model is a significantly better fit than the
    null.
6.  

```{r core_GLM_chi_scorer}

core_GLM_chi_scorer <- function(
        input,  # the full combined dataset
        start_col = 21,  # the column where the genotype data starts
        col_to_use = "NULL",
        test_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat + precip_yr ", 
        null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)", 
        format_table = FALSE
        
  ){
  
  library(dplyr)
  
  # define columns to use
  if (col_to_use[1] == "NULL") { 
    col_pos <- c(
      start_col:ncol(input)
    ) 
  } else {
    col_pos <- col_to_use
  }
  
  # start loop
  for (i in col_pos){
    
    tryCatch({  # open a catch test 
    
    glm_gt_data_bi <- input %>% # remove third alleles (i.e. only have biallelic sites)
      filter_at(
        vars(i), 
        all_vars(. == 1 | . == 0)
      )
    
    # select position
    snp <- names(  # test data without 2s... 
      glm_gt_data_bi
    )[i]
    
    snp_pos <- stringr::str_extract(
      string = snp, 
      pattern = "\\d+" # extract digits 
    )
    
    # create formula
    formula <- as.formula(
      paste(
        snp, test_formula # combine the snp position with the covariates
      )
    )
    
    # run model with environmental variables
    mod <- lme4::glmer( 
      data = glm_gt_data_bi,
      formula = formula ,
      family = "binomial", 
      control = lme4::glmerControl(
        optimizer = "bobyqa", 
        optCtrl = list(maxfun = 100000)
      )
    )
    
    # create anova table:
    chisq_df <- as.data.frame(
      drop1( # this performs the drop-test (sequentially removes variables from the full model)
        mod, 
        test="Chisq",  # this is synonomous with the LRT test 
        na.rm = TRUE
      )
    )
    
    # create Null formula
    formula_null <- as.formula(
      paste(
        snp, null_formula
      )
    )
    
    # create null model with patristic distance
    null_mod <- lme4::glmer( 
      data = glm_gt_data_bi,
      formula = formula_null ,
      family = "binomial", 
      control = lme4::glmerControl(
        optimizer = "bobyqa", 
        optCtrl = list(maxfun = 100000)
      )
    )
    
    # compare null and full model 
    null_df <- as.data.frame(
      anova(
        mod,  
        null_mod,
        test = "Chisq"
      )
    )
    
    # calculate overdispersion ratios for the full model
    glm_overdisp <- overdisp_fun(mod)
    
    # combine with snp value
    chisq_df <- cbind(
      chisq_df, 
      snp_pos, 
      glm_overdisp[2], 
      null_df$`Pr(>Chisq)`[2]
    )   
    
    # include the covariates
    chisq_df <- chisq_df %>%
      mutate(covariate = rownames(chisq_df))
    
    if (i == col_pos[1]){
      # for the first SNP make a new table of scores
      chisq_scores_pcs <- chisq_df
    } else {
      # for subsequent SNPs append to this table
      chisq_scores_pcs <- rbind(
        chisq_scores_pcs, 
        chisq_df
      )
    }
    
    if (i == tail(col_pos, 1)
        ){
      
      # for the last SNP append then return the table
      chisq_scores_pcs$snp_pos <- as.numeric(chisq_scores_pcs$snp_pos)
      
      return(chisq_scores_pcs)
    }
    
    message(
      paste(
        snp , " - Chi Squared scores calculated"
      )
    )
    
    message(
      paste(
        i-start_col , "/" , length(col_pos)-start_col, " positions completed"
      )
    )
    
    }, 
    error = function(e) {  # define what to do if an error occurs
      message( 
        paste(
          "Model did not converge for SNP", col_pos[i], "- Skipping to the next SNP"
        )
      )
    }
    ) # close Catch loop
    
    if (i == col_pos[length(col_pos)]
        ){
      return(chisq_scores_pcs)
    }
    
  }
  
  message("All Chi Squared Scores returned")
  
}
```

```{r core_GLM_scorer_parallel}

# this function is a wrapper that allows the core_GLM_chi_scorer to be run over multiple computer cores in parallel - hopefully this should speed things up... 

core_GLM_scorer_parallel <- function(
        input, 
        start_col = 24, 
        col_to_use = NULL,
        test_formula , 
        null_formula , 
        format_table = NULL, 
        num_cores = 1 
) {
  
  # define blocks of SNPs to have in each chunk
  col_chunks <- split(
    start_col:ncol(input), 
    ceiling(
      seq_along(start_col:ncol(input)) / num_cores
    )
  )
  
  message(
    paste(
      num_cores, "cores used"
    )
  )
  
  
  results <- parallel::mclapply(
    col_chunks, 
    function(chunk){
      
      adj_start <- start_col + min(chunk) -1
      
      core_GLM_chi_scorer(
        input, 
        start_col = adj_start, 
        col_to_use = chunk, 
        test_formula, 
        null_formula
      )
    }, 
    mc.cores = num_cores
  )
  
  result_df <- do.call(rbind, results)
  
  return(result_df)
  
}


```

```{r core_GLM_formatter}

core_GLM_formatter <- function(
        input, 
        cutoff_quantile = 0.05, # the level to label
        overdisp_limits = c(0.75, 1.25), # the default upper and lower dispertion limits
        neaten = TRUE,
        alpha = 0.05
) {
  
  table <- input
  
  # rename annoying columns
  names(table)[c(6,7)] <- c("overdisp", "null_chisq")
  
  # filter out sites that do not pass the dispersion filters 
  table <- table %>%
    filter(
      overdisp >= overdisp_limits[1] & overdisp <= overdisp_limits[2]
    )
  
  # calculate the number of remaining SNPs 
  n_snps <- length(unique(table$snp_pos))
  
  message(
    paste0(
      n_snps, " remaining after dispersion filtering. /n", 
      overdisp_limits, " used as the upper and lower limits for dispersion ratios"
    )
  )
  
  # calculate the bon_ferroni threshold for SNPs that pass chi with the null 
  bon_threshold_null <- alpha/(n_snps*1) # 1 test conducted
  
  message(
    paste(
      alpha,
      " used as the alpha value for significance."
    )
  )
  
  message(
    paste(
      bon_threshold_null , "used as the bonferroni corrected threshold value"
    )
  )
  
  # add labels for each SNP - does the Full model perform significantly better than the Null?
  table$null_label[table$null_chisq <= bon_threshold_null] <- "T"
  table$null_label[table$null_chisq >= bon_threshold_null] <- "F"
  
  # add a label column 
  table$labels <- table$snp_pos
  
  # determine the top 5% cutoff (or as defined in the input)
  cutoff <- as.numeric(
    quantile(
      table$`Pr(Chi)`, 
      cutoff_quantile, 
      na.rm = TRUE
    )
  )
  # only include the labels for those above this threshold 
  table$labels[table$`Pr(Chi)` >= cutoff ] <- ""

  if (neaten == TRUE) {
  # filter results to neaten plot
    table <- table %>%
      filter(covariate != "PC.") 
  }
  
  return(table)
}

```


## Comparing with the Null

Whereby the Null model only includes the measure of genetic relatedness ( PCs)
and a random variable.

See below for the code to run on the down-sampled individuals (recommended).

```{r core_GLM_scores, include=FALSE}
# -----= WARNING: THIS RUNS ON ALL INDIVIDUALS - NOT ADVISED -----------
# running across all individuals (not downsampled)
core_GLM_scores_pc <- core_GLM_chi_scorer(
  input = lhf_gt_meta_pc, 
  start_col = 24, 
  test_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat + precip_yr ", 
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)"
)

```

```{r core_GLM_scores_downsampled}

system.time(
core_GLM_scores_ds <- core_GLM_chi_scorer(
  input = lhf_gt_meta_pc_ds, 
  start_col = 24,
  test_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat + precip_yr ", 
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)"
)
)

# 24-160 run initially
# running on downsampled dataset in 3 halves...
system.time(
#core_GLM_scores_ds <- core_GLM_scorer_parallel(
  input = lhf_gt_meta_pc_ds, 
  start_col = 468,
  test_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat + precip_yr ", 
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)",
  num_cores = 2
)
)


```

```{r save_core_GLM}

# saving the core GLM scores when PCs are used as the measure of relatedness & the downsampled data is used
feather::write_feather(
  x = core_GLM_scores_ds, 
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_DOWNSAMPLED_05_2024.feather" # date changed
)

# saving the core GLM scores when PCs are used as the measure of relatedness
#feather::write_feather(
#  x = core_GLM_scores_pc, 
#  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_05_2024.feather" # date changed
#)

# saving the GLM scores for when Patristic Distances were used as an indicator 
#feather::write_feather(
#  x = core_GLM_scores, 
#  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_02_2024.feather"
#)

```

### Read in GLM scores

```{r read_core_GLM_scores}

# ensure you call in the correct file here!!!
# --- here we are calling in the DOWNSAMPLED data!
core_GLM_scores <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_DOWNSAMPLED_05_2024.feather"
)

```


## Format & filtering outputs

```{r format_core_GLM_scores}

core_GLM_scores_formatted <- core_GLM_formatter(
  input = core_GLM_scores,  # full table with GLM scores
  cutoff_quantile = 0.05,   # which values to include labels for 
  overdisp_limits = c(0.8, 200), # the upper and lower bounds for overdispertion ratios
  neaten = FALSE, 
  alpha = 0.01
)
```

```{r format_core_GLM_scores_phased}
core_GLM_scores_formatted_phased <- left_join(
  x = core_GLM_scores_formatted, 
  y = rCRS, 
  by = join_by("snp_pos" == "aln_pos")
)

#feather::write_feather(
  x = core_GLM_scores_formatted_phased, 
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_formatted_phased_ds_07_2024.feather" # date changed
)

core_GLM_scores_formatted_phased <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_formatted_phased_ds_07_2024.feather" # date changed
)

```

```{r save_formatted_meta}
# convert SNP values to match column names
pos_subset <- str_c(
  "pos_", unique(core_GLM_scores_formatted_phased$snp_pos), 
  sep = ""
)

# select the columns that match the metadata and SNP hits 
lhf_gt_meta_ds_subset <- lhf_gt_meta_pc_ds %>%
  select(
    acc:precip_seasonality,
    all_of(
      pos_subset
    )#, 
   # pos_3060, pos_3557, pos_3970
  )

names(lhf_gt_meta_ds_subset)

feather::write_feather(
  x = lhf_gt_meta_ds_subset, 
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pc_ds_subset_07_2024.feather" # date changed
)

```

```{r match_SNPs_classification}

SNPs_list <- unique(core_GLM_scores_formatted_phased$rCRS_pos)

SNPs_list <- tibble(
  pos = SNPs_list
)

SNPs_list <- left_join(
  SNPs_list, 
  mt_loci_pos, 
  by = join_by(pos >= Starting, pos <= Ending)
)

SNP_classification_N <- SNPs_list %>%
  group_by(Map.Locus) %>%
  reframe(
    N = n()
  )

feather::write_feather(
  x = SNP_classification_N, 
  path = "~/Documents/data/lhf_d/feather/SNP_classification_N.feather"
)
```

```{r core_minimum_models}

# select SNPs where the alternative model performs significantly better
core_GLM_min_null <- core_GLM_scores_formatted_phased  %>%
  filter(null_label == "T" & covariate == "<none>") %>%
  select(
    snp_pos, rCRS_pos, overdisp, null_chisq, value
  )

# add in mt loci data
core_GLM_min_null <- left_join(
  core_GLM_min_null, 
  mt_loci_pos, 
  by = join_by(
    rCRS_pos >= Starting, 
    rCRS_pos <= Ending
  )
)

# save this file
feather::write_feather(
  x = core_GLM_min_null, 
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_mins_ds_07_2024.feather" # date changed
)
```

```{r core_GLM_hits_formatting}

# define the threshold
alpha <- 0.01

# only inclde SNPs where the full model performs significantly better than the null
core_GLM_hits <- core_GLM_scores_formatted_phased  %>%
  filter(null_label == "T")

length(unique(core_GLM_hits$rCRS_pos))

# check that one of the PCs is a significant predictor for every SNP
core_GLM_hits_pc <- core_GLM_hits %>%
  group_by(snp_pos) %>%
  filter(covariate %in% c("PC1", "PC2", "PC3", "PC4")) %>% 
  slice_min(`Pr(Chi)`) %>%
  filter(`Pr(Chi)` > alpha/(length(unique(core_GLM_hits$snp_pos))*6))
# this table should be empty

message(
  "Checking if all SNPs have at least one of the PCs as a significant predictor"
)
nrow(core_GLM_hits_pc) == 0 # should be TRUE
# ------ All SNPs are significantly predicted by at least one of the PCs

core_GLM_hits_pc <- core_GLM_hits %>%  # reformat without removing lat and precip
  group_by(snp_pos) %>%
  slice_min(`Pr(Chi)`) %>%
  select(snp_pos, rCRS_pos, covariate, `Pr(Chi)`) %>%
  group_by(covariate)
# this calculates which is the most sigificant predictor for each SNP 
# -- for 3 SNPs lat is the strongest predictor

n_snp_hits <- length(unique(core_GLM_hits$snp_pos))

core_GLM_hits <- core_GLM_hits %>%
  filter(covariate %in% c("lat","precip_yr")) %>%
  filter(`Pr(Chi)` <= alpha/(n_snp_hits*6)) 
# this gives all the hits for latitude and precipitation  - should I keep all of these anyway?

# calculate the remaining number of SNPs 
n_snp_hits <- length(unique(core_GLM_hits$rCRS_pos))
n_snp_hits

bon_threshold_hits <- alpha/(n_snp_hits*6) # is this 2 or 3?
 # check here whether they get better or worse 

```

All SNPs are significantly predicted by at least one of the PCs - my
interpretation of this is that this measure of genetic relatedness is a
reasonable estimate.

# Generating PCA Plots

PCA plots can be used to visualise the distribution of the data.

```{r PCA_plots, echo=TRUE}

# plotting PC1 vs PC2
ggplot2::ggplot(
  data = lhf_pca_scores, 
  mapping = ggplot2::aes(
    x = PC1, 
    y = PC2, 
    col = continent
  )
) +
  ggplot2::geom_point(
) +
  ggplot2::scale_colour_manual(
    values = FiGT_continent_palette 
) + 
  ggplot2::xlab(
    "PC1 (19.09%)"
  ) + 
  ggplot2::ylab(
    "PC2 (11.77)"
  ) + 
  ggplot2::theme_minimal()+ 
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      size = 15
    ),
     axis.text.y = ggplot2::element_text(
      size = 15
    ), 
    axis.title = element_text(
      size = 25
    )
  ) + 
  transparent_theme

ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/General/Presentations/Figures/lhf_downsampled_PC1vsPC2.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 7
)
  

# plotting PC3 vs PC4
 ggplot2::ggplot(
   data = vcf.pca.scores, 
   mapping = ggplot2::aes(
     x = PC3, 
     y = PC4, 
     col = continent
   )
) +
ggplot2::geom_point(
) +
  ggplot2::scale_colour_manual(
    values = c(
      "deepskyblue4", "firebrick4", "orchid3", "chartreuse4", "turquoise",
  "chartreuse3"
    )
  ) + 
  ggplot2::xlab(
    "PC3 (7.15%)"
  ) + 
  ggplot2::ylab(
    "PC4 (5.76)"
  ) + 
  ggplot2::theme_minimal(
  )+ 
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      size = 15
    ),
     axis.text.y = ggplot2::element_text(
      size = 15
    ), 
    axis.title = element_text(
      size = 25
    ), 
    legend.position = "none"
  ) + 
  transparent_theme

ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/General/Presentations/Figures/lhf_downsampled_PC3vsPC4.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 7
)
```

# Plotting GLM results

After the GLM models have been run and compared, the data can be visualised by a
through different plotting methods.

## Null vs Full models

The first test completed on each of the SNPs is whether the full model (with
Latitude and annual precipitation) fits the data significantly better than the
null (PCs alone).

The threshold of significance here is the alpha value (0.01) divided by the
number of SNPs that pass the dispersion filters multiplied by the number of
tests (in this instance 1). This is the same as the Bonferroni corrected
p-value.

```{r manhattan_null, warning=FALSE}

alpha <- 0.01

n_snps <-  length(unique(core_GLM_scores_formatted$snp_pos)) # change depending on the output from format_core_GLM_scores
bon_threshold_null <- alpha/(n_snps*1)

ggplot2::ggplot(
  data = core_GLM_scores_formatted_phased, 
  mapping = aes(
    x = rCRS_pos,
    y = log10(null_chisq)
  )
) +
  geom_point(
    colour = "darkorchid", 
    size = 3
  ) +
  geom_line(
    y = -1*log10(bon_threshold_null), 
    colour = "black", 
    linewidth = 1,
  ) + 
  scale_x_continuous(
    breaks = seq(0,17000, 1000)
  ) +
  ylim(c(1, -18)
  ) +
  ylab(
    "Logged 10 P-value"
  ) +
  xlab(
    "Position (relative to rCRS)"
  ) +
  geom_segment(
    data = mt_loci_pos,
    ggplot2::aes(
      x = Starting, 
      #x = aln_start,
      xend = Ending, 
      #xend = aln_end,
      y = 0.5, 
      yend = 0.5, 
      col = classification
    ),
    linewidth = 3, 
    alpha = 0.7, 
    position = ggplot2::position_jitter(
      height = 0.1
    )
  ) +
  scale_colour_manual(
    values = c(
      mtDNA_palette
    )
  ) +
  theme_minimal()+
  theme(
    legend.position = "none", 
    axis.line = ggplot2::element_line(
      linewidth = 1, 
      colour = "black"
    ), 
    plot.background = ggplot2::element_rect(
      fill = "white"
    ), 
    panel.grid = ggplot2::element_line(
      colour = "white", 
      linetype = "dotdash"
    ),
    panel.grid.major.x = ggplot2::element_line(
      colour = "snow4", 
      linetype = "dashed"
    ), 
    legend.background = ggplot2::element_rect(
      fill = "white"
    ), 
    axis.title = element_text(
      size = 20
    ),
    axis.text = element_text(
      size = 14
    )
  ) +
  transparent_theme

```

```{r save_core_manhattan}
ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/General/Presentations/Figures/lhf_core_GLM_07_2024.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 7
)
```

This figure shows that a number of SNPs are significantly better explained by
the full model with latitude and precipitation rather than the null model alone.

> **At the very least this result alone indicates that mitochondrial DNA may not
> be evolving as neutrally as once thought...**


