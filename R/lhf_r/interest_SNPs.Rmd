---
title: "SNPs of Interest"
author: "FiG-T"
data: "`r Sys.Date()`"
output: 
  html_document: 
    keep_md: yes
    toc: yes
toc: TRUE
editor_options:
  markdown:
    wrap: 80
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE}

# load required libraries
library(feather)
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyr)
library(lme4)
```

```{r colour_palettes}

source("https://raw.githubusercontent.com/FiG-T/scripts/main/R/lhf_r/colour_palettes.R")
```

```{r additional_source_files_required}
## ----- FIX this ?
source("https://raw.githubusercontent.com/FiG-T/scripts/main/R/lhf_r/mtDNA_loci.R")
```

# Introduction

From the "core" GLMs models (where an alternative model with Lat and Precip was
compared to a null) we can see there is potential evidence that mtDNA genotype
distributions are significantly associated with a combination of environmental
variables.

This script focuses partly on looking at where these SNPs lie (*vis a vis*
loci), and partly on a second stage of model testing which takes paleoclimate,
plant, and disease outbreak dataset and applies them to the mtDNA genotype
distributions from before. For information on how to curate these three
data-sets please see "lhf_st2_metadata_curation.Rmd".

# Data

The data required to run this script have all been previously generated. Please
see the listed script for further information.

```{r import data}

# importing the phased GLM scores using the downsampled data (see LHF_core_GLMs.Rmd)
core_GLM_scores_formatted_phased <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_formatted_phased_ds_07_2024.feather"
)

# importing the list of significant hits  
core_GLM_min_null <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/core_GLM_scores_mins_ds_07_2024.feather"
)


# mtDNA loci positioning  - see mtDNA_loci.R
mt_loci_pos <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/mtDNA_loci_all_positions_classifications.feather"
)

# list of all loci and the number of SNPs they contain (see LHF_core_GLMs.Rmd)
SNP_classification_N <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/SNP_classification_N.feather"
)

# the downsampled data containing the environmental metadata
lhf_gt_meta_ds_subset <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pc_ds_subset_07_2024.feather"  
)

# import combined paleoclimate, plant, and disease data (see lhf_st2_metadata_curation.Rmd)
paleo_wcvp_outbreaks <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_meta_paleo_wcvp_outbreaks_05_2024.feather"
)

### -- check which of these is required
#mutations_Cfrm <- read.csv(
#  file = "~/Documents/data/lhf_d/mutations_Cfrm_MITOMAP_2024_05_13.csv"
#)
#mutations_all <- read.csv(
#  file = "~/Documents/data/lhf_d/Mutations_all_MITOMAP.csv"
#)

vep <- read.csv(
  file = "~/Documents/data/lhf_d/ensembl_VEP_formatted_specific.csv"
)

```

```{r order_factors}

# combine the list of significant SNPs with the table showing the number of SNPs at each locus
core_GLM_min_null$Map.Locus <- factor( # arrange the locus into the order you want to plot them in
  x = core_GLM_min_null$Map.Locus, 
  levels = c(
    "MT-ATT", "MT-CR", # Attachment site and control region
    "MT-7SDNA", "MT-HV1", "MT-HV2", 
    "MT-OHR",  "MT-TAS2",  "MT-TFX" ,
    "MT-ND1", "MT-ND2", "MT-ND3", "MT-ND4", "MT-ND5", "MT-ND6",
    "MT-CYB",
    "MT-CO1","MT-CO2", "MT-CO3", 
    "MT-ATP6", "ATP8",
    "MT-RNR1", "MT-RNR2",
    "Humanin", "MT-SHLP3", "MT-SHLP6", 
    "MT-TT", "MT-TG", "MT-TR", "MT-TH" 
  )
)
```

## Hits Positioning

Once we have our lift of SNPs that are significantly better explained by the
alternative model (which includes environmental variables) we can see where they
fall within the mitochondrial genome and assess for each loci what percentage of
SNPs are significant.

```{r adding_classification_snp_no. }

# combine GLM results with total number of SNPs per loci
interest_snps <- left_join(
  core_GLM_min_null,
  SNP_classification_N, 
  by = "Map.Locus"
)
 
interest_snps <- interest_snps %>%
  group_by(Map.Locus) %>% # for each locus...
  reframe(
    classification = classification, 
    classification_length = classification_length,
    locus_snps = N, 
    N_hits = n()   # ...count the number of hits 
  ) %>%
  distinct() %>%
  mutate(
    per_snps = (N_hits/locus_snps)*100, # calculate the percentage of SNPs which are hits
    per_loci = (N_hits/classification_length) * 100  # calcuate percentage of bp which are hits
  )

interest_snps$Map.Locus <- factor( # arrange the locus into the order you want to plot them in
  x = interest_snps$Map.Locus, 
  levels = c(
    "MT-ATT", "MT-CR", # Attachment site and control region
    "MT-7SDNA", "MT-HV1", "MT-HV2",
    "MT-OHR",  "MT-TAS2",  "MT-TFX" ,
    "MT-ND1", "MT-ND2", "MT-ND3", "MT-ND4", "MT-ND5", "MT-ND6",  # complex I
    "MT-CYB", # complex III
    "MT-CO1","MT-CO2", "MT-CO3", # complex IV
    "MT-ATP6", "ATP8", # complex V
    "MT-RNR1", "MT-RNR2", # ribosomal RNA 
    "Humanin","MT-SHLP3", "MT-SHLP6",   # Humanin and Humanin like peptides
    "MT-TT", "MT-TG", "MT-TR", "MT-TH"  # transferRNA genes 
  )
)
```

```{r snp_hits_overview_bar}

ggplot(
  data = interest_snps,  # generated in the chunk above
  mapping = aes(
    x = Map.Locus, # plot by the specific loci
    y = per_snps, 
    fill = classification # colour by the broader classification
  )
) + 
  geom_bar(
    stat = "identity", 
    show.legend = FALSE
  ) +
  ggplot2::scale_fill_manual(
    values = mtDNA_palette # see palette above
  ) +
  geom_text(
    mapping = aes(
      label = N_hits
    ), 
    colour = "black", 
    nudge_y = 5
  ) +
  #facet_grid(
  #  cols = vars(
  #    Map.Locus
  #  )
  #) +
  ylab(
    "Percentage of SNPs with \n significant hits (%)"
  ) +
  xlab(
    "mtDNA Loci"
  )  +
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      angle = 90,
      vjust = 0.1,
      hjust = 0.1,
      size = 12
    ),
     axis.text.y = ggplot2::element_text(
      size = 12
    ),
    axis.title.y = ggplot2::element_text(
      size = 18
    )
  ) + 
  transparent_theme

#ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/figures/lhf_hits_loci_overview_08_2024.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 7
)

```

This plot shows that :

-   the control region (a.ka. the D-loop) may be important for environmental
    adaptation.

-   there is significant variability across ETC complex subunits (e.g, ND2 has
    \~25% vs ND4L 0%)

-   Complex I is not markedly higher than other complexes (when looking at the
    proportions of SNPs that are significant).

-   transferRNAs have few SNPs, but these are frequently significant

-   rRNAs (and SHLP) have comparable levels of significant sites to protein
    coding regions.

We can also look at which SNPs are shared between multiple loci (and which SNPs
are most significant).

```{r hits_dotplot}
  
ggplot2::ggplot(
  data = core_GLM_min_null, # using the significant hits 
  mapping = aes(
    x = as.factor(rCRS_pos), 
    y = Map.Locus, 
    colour = log10(null_chisq)
  )
)  + geom_point(
  size = 5
) +
  xlab(
    "SNP rCRS postion"
  ) +
  ylab(
    "mtDNA locus"
  ) +
  labs(
    colour = "Log10 Chisq Score"
  )+
  theme_grey(
  )+ 
  theme(
    axis.text.x = element_text(
      angle = 90, 
      vjust = 0.5
    ), 
    legend.title = element_text(
      
    )
  ) 
```

```{r save_multiple_dotplot}
#ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/figures/lhf_hits_loci_dotplot_08_2024.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 7
)
```

This plot is interesting in that it highlights a couple of things I didn't
notice before...

1.  The strongest hit (**250**) within the control region also falls within the
    mitochondrial transcription factor binding site (mtTFX). The second
    strongest signal (199) is also highly correlated with this pos250.
2.  Both hits within 16S RNA (RNR2) also fall within SHLP region - could this be
    important?
3.  ND4 has both the (joint) largest number of significant SNPs for a protein
    coding locus and two of these (**11674** & **11947**) are among the
    strongest signals we observe (based on the "core" GLMs).

# Adding additional metadata

In the "core" models used so far, latitude and annual precipitation have been
used as a proxy for general 'environmental variables'. Latitude strongly
correlates with temperature variables, and precipitation captures a different
set of the variance. Both have been used in previous studies.

While these early models have been useful for addressing broad questions, it is
hard to link them to specific ecological explanations. This problem may in part
be solved by the use of more specific environmental variables which allow for
greater interpretation of the results. The second stage of this analysis thus
involves re-running the analysis using a mixture of reconstructed paleoclimate,
plant, and disease outbreaks measures and variables. For a more detailed
breakdown of how these variables were curated please see
"lhf_st2_metadata_curation.Rmd".

```{r combine_extra_metadata}

# merge with genotype data
lhf_gt_pc_st2_meta <- left_join(
  x = lhf_gt_meta_ds_subset,  # using the same subset of downsampled individuals as before. 
  y = paleo_wcvp_outbreaks, # adding in the curated additional metadata
  by = "iso3"
)

# reorder columns
lhf_gt_pc_st2_meta <- lhf_gt_pc_st2_meta %>%
  select(
    acc:precip_seasonality, area, 
    native:outbreaks_area, 
    mean_T_yr_paleo:lai_paleo, 
    pos_156:pos_16464
  )

names(lhf_gt_pc_st2_meta)[c(7, 12)] <- c("country", "iso2")
```

These variables all also need to be scaled before use in the GLMM.

```{r scale_st2_meta}

for (x in c(25:42)){ # check that these align with the right columns
  
  col <- names(lhf_gt_pc_st2_meta)[x]
  
  lhf_gt_pc_st2_meta[[col]] <- scale(lhf_gt_pc_st2_meta[[col]])
}
```

```{r save_st_metafile}

#feather::write_feather(
  x = lhf_gt_pc_st2_meta, 
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pc_ds_subset_full_07_2024.feather"
)

lhf_gt_pc_st2_meta <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_gt_meta_pc_ds_subset_full_07_2024.feather"
)
```

# Testing Multiple Models

Rather than completing a (relatively) simple "does model 2 perform better than
model 1" test, we now have many comparisons to make. I.e "how do models
2,3,4,5... compare to model 1?". This requires a slightly different function.

To help speed up this process slightly there is also a new wrapper function that
allows the GLM multi-scorer to run on multiple computer cores in parallel
(typically R is single threaded and thus only uses one). See [Running on
multiple cores] for more details.

## Functions

This function builds a model for each test formula supplied an compares them to
the same null model (which only includes Principal Components and random
variables as before).

```{r GLM_multi_scorer_function}

# define function for later use
GLM_multi_scorer <- function(
        input,  # the data to use
        start_col = 43, # where the genotype information starts
        col_to_use = "NULL",
        test_formulas = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat + precip_yr ", 
        null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)", 
        format_table = FALSE # should the output be returned as a list (default) or a table?
        
  ){
  
  library(dplyr)
  
  # define columns to use
  if (col_to_use[1] == "NULL") { 
    col_pos <- c(
      start_col:ncol(input)
    ) 
  } else {
    col_pos <- col_to_use
  }
  
  chisq_scores <- list()  # initiate an empty list 
  
  # start loop
  for (i in col_pos){  # for each column with genotype data
    
    glm_gt_bi <- input %>%
      filter_at(
        vars(i), 
        all_vars(. == 1 | . == 0)  # only include 2 alleles
      )
    
    message( paste(
      nrow(glm_gt_bi), 
      " columns in dataset"
    )
    )
    
    # select position
    snp <- names(  # test data without 2s... 
      glm_gt_bi
    )[i]
    
    message(snp)
    
    snp_pos <- stringr::str_extract(  # define the SNP being modelled
      string = snp, 
      pattern = "\\d+"
    )
    
    message(snp_pos)
    
     # create Null formula
    formula_null <- as.formula(
      paste(
        snp, null_formula # combine the NULL formula from above with the column with SNP data. 
      )
    )
    
    # create null model with 
    null_mod <- lme4::glmer( 
      data = glm_gt_bi,
      formula = formula_null ,
      family = "binomial",  # as the genotype data is either 1 or 0 
      control = lme4::glmerControl(
        optimizer = "bobyqa", 
        optCtrl = list(maxfun = 1000000)
      )
    )
    #print(null_mod)
    
    #print(anova(null_mod))
    
    chi_sqs <- list() # initiate and empty list
    
    for (i in seq_along(test_formulas)){ # for each test formula... 
      
      tryCatch({  # open a catch test
      
      formula <- as.formula(
        paste(
          snp, test_formulas[i] # pair with SNP under investigation
        )
      )
      
      # run model
      mod <- lme4::glmer( 
        data = glm_gt_bi,
        formula = formula ,
        family = "binomial", 
        control = lme4::glmerControl(
          optimizer = "bobyqa", 
          optCtrl = list(maxfun = 100000)
        )
      )
      
      #print(mod)
      #print(summary(mod))
      
      # compare null and full model 
      null_df <- as.data.frame(
        anova(
          null_mod, 
          mod, 
          test = "Chisq"
        )
      )
      
      #print(null_df)
      
      chisq_df <- cbind( 
        # bind the anova together to the SNP position and the formula being used. 
        null_df, 
        snp_pos,
        test_formulas[i] 
      ) 
      
      message("anova scores created")
      
      chi_sqs[[i]] <- chisq_df # add this table into the intiated list
      
      #print(chi_sqs[[i]])
      
      }, 
      error = function(e) {  # define what to do if an error occurs
      message( 
        paste(
          "Model did not converge for", test_formulas[i], "- Skipping to the next test formula. 
          --------------------------------------------------------"
        )
      )
    }
  ) # close Catch loop
      
    } # close test formula loop
    
    # add this list of tables (for each formula per snp) to a larger list 
    chisq_scores[[snp]] <- chi_sqs 
    
    message("Scores added into big list")
    # calculate overdispersion
   # glm_overdisp <- overdisp_fun(mod)
    
    message(
      paste(
        snp , " - Chi Squared scores calculated"
      )
    )
  
  }
  message("All Chi Squared Scores returned")
  
  if (format_table == TRUE) { 
    # if table output is specified merge the lists together... 
    chisq_scores <- bind_rows(chisq_scores)
  }
  
  return(chisq_scores)
  
  #if(format_table == FALSE){
  #  return(chisq_scores_patr)
  #} 
  
}
```

### Running on multiple cores 

This function divides the SNPs across the number of cores stated. Ensure that
you have enough cores on your machine to meet the number you specify.

```{r core_GLM_multi_scorer_parallel}
core_GLM_multi_scorer_parallel <- function(
        input, 
        start_col = 43, 
        col_to_use = NULL,
        test_formula , 
        null_formula , 
        format_table = NULL, 
        num_cores = 1 
) {
  # define blocks of SNPs to have in each chunk
  col_chunks <- split(
    start_col:ncol(input), 
    ceiling(
      seq_along(start_col:ncol(input)) / num_cores
    )
  )
  
  message(
    paste(
      num_cores, "cores used"
    )
  )
  
  results <- parallel::mclapply(
    col_chunks, 
    function(chunk){
      
      adj_start <- start_col + min(chunk) -1
      
      GLM_chi_multi_scorer(
        input, 
        start_col = adj_start, 
        chunk, 
        test_formula, 
        null_formula
      )
    }, 
    mc.cores = num_cores
  )
  
  result_df <- do.call(rbind, results)
  
  return(result_df)
  
}
```

## Running GLMM tests

Define the test formulas that you wish to run:

Here paleo factors are separated out as there are 198 individuals from Tonga and
the Cook Islands for which no paleo reconstructions are available. This thus
requires a slightly separate null (which also has none of these individuals) so
that a Likelihood Ratio test can be performed on both models.

```{r test_formulas}
# define the formulas WITHOUT the response variable
test_formulas <- c(
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + precip_yr",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + tmp_max",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + tmp_min", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + native_area", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + endemic_area",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + outbreaks_area"
)

test_formulas_paleo <- c(
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + mean_T_yr_paleo",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + T_seasonality_paleo",  
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + T_wetQ_paleo",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + T_dryQ_paleo", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + mean_T_warmQ_paleo",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + mean_T_coldQ_paleo", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + precip_yr_paleo", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + precip_dryQ_paleo", 
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + precip_coldQ_paleo",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + npp_paleo",
  "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lai_paleo"
)


```

```{r non_paleo_countries}
# generate a list of countries that are not in the paleo dataset 
non_paleo_iso <- lhf_gt_pc_st2_meta %>%
  filter(is.na(mean_T_yr_paleo)) %>%
  select(iso2) 

# convert this into a vector
non_paleo_iso <-  unique(non_paleo_iso$iso2)
```

```{r run_multi_scorer}

# run the test formulas without paleo variables 
lhf_st2_GLM_scores <- core_GLM_multi_scorer_parallel(
  input = lhf_gt_pc_st2_meta, 
  start_col = 43, 
  num_cores = 6, 
  test_formula = test_formulas, 
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)", 
  format_table = TRUE
)

# run the paleovariables on the first batch of SNPs
lhf_st2_GLM_scores_paleo <- core_GLM_multi_scorer_parallel(
  input = lhf_gt_pc_st2_meta[,c(1:130)] %>%
    filter( ! iso2 %in% non_paleo_iso) , # removing problem countries
  start_col = 43, 
  num_cores = 6, 
  test_formula = test_formulas_paleo, 
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)", 
  format_table = TRUE
)

# run on second batch of SNPs
lhf_st2_GLM_scores_paleo_ii <- core_GLM_multi_scorer_parallel(
  input = lhf_gt_pc_st2_meta %>%
    filter( ! iso2 %in% non_paleo_iso) %>%
    select(! pos_9109), # this SNP is problematic...? Not sure why
  start_col = 131, 
  num_cores = 5,
  test_formula = test_formulas_paleo, 
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2)", 
  format_table = TRUE
)

# combine score lists into tables
lhf_st2_GLM_scores_tb <- dplyr::bind_rows(lhf_st2_GLM_scores, .id = "Check Number")

lhf_st2_GLM_scores_paleo_tb <- dplyr::bind_rows(lhf_st2_GLM_scores_paleo, .id = "Check Number")

lhf_st2_GLM_scores_paleo_tb_ii <- dplyr::bind_rows(lhf_st2_GLM_scores_paleo_ii, .id = "Check Number")
```

```{r run_interaction_scorer, include=FALSE}
lhf_st2_GLM_scores_interact <- core_GLM_multi_scorer_parallel(
  input = lhf_gt_pc_st2_meta, 
  start_col = 43, 
  num_cores = 6, 
  test_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat * precip_yr",  # include interaction
  null_formula = "~ PC1 + PC2 + PC3 + PC4 + (1|iso2) + lat + precip_yr", 
  format_table = TRUE
)

lhf_st2_GLM_scores_interact_tb <- dplyr::bind_rows(lhf_st2_GLM_scores_interact, .id = "Check Number")

```

```{r format_st2_hits}

# combine all the results into a single table
lhf_st2_GLMM_scores <- rbind(
  lhf_st2_GLM_scores_tb, 
  lhf_st2_GLM_scores_paleo_tb, 
  lhf_st2_GLM_scores_paleo_tb_ii
)

# remove the null models
lhf_st2_GLMM_scores <- lhf_st2_GLMM_scores %>%
  filter(!is.na(Chisq))

# convert positions to numeric
lhf_st2_GLMM_scores$snp_pos <- as.numeric(lhf_st2_GLMM_scores$snp_pos)

# extract covariate names 
lhf_st2_GLMM_scores$covariate <- str_extract(
  string = lhf_st2_GLMM_scores$`test_formulas[i]`, 
  pattern =  "tmp_max|tmp_min|tmp_yr|tmp_range_drl|isotherm|tmp_seasonality|tmp_range_yr|lat|mean_T_yr_paleo|T_seasonality_paleo|T_wetQ_paleo|T_dryQ_paleo|mean_T_warmQ_paleo|mean_T_coldQ_paleo|precip_yr_paleo|precip_dryQ_paleo|precip_coldQ_paleo|npp_paleo|lai_paleo|native_area|endemic_area|outbreaks_area|precip_yr" 
)

# bind to rCRS positions
lhf_st2_GLMM_scores <- left_join(
  x = lhf_st2_GLMM_scores, 
  y = rCRS, 
  by = join_by("snp_pos" == "aln_pos")
)

# calculate the log10 of the chisq scores
lhf_st2_GLMM_scores$log10_scores <- log10(lhf_st2_GLMM_scores$`Pr(>Chisq)`)

```

```{r save_st2_hits}
#feather::write_feather(
  x = lhf_st2_GLMM_scores, 
  path = "~/Documents/data/lhf_d/feather/lhf_st2_GLMM_scores_08_2024.feather"
)

lhf_st2_GLMM_scores <- feather::read_feather(
  path = "~/Documents/data/lhf_d/feather/lhf_st2_GLMM_scores_08_2024.feather"
)  
  
#feather::write_feather(
  x = lhf_st2_GLM_scores_paleo_tb, 
  path = "~/Documents/data/lhf_d/feather/lhf_st2_GLMM_scores_paleo_08_2024.feather"
)
```

```{r st2_GLMM_scores_w , include=FALSE}
# convert to wide format
lhf_st2_GLMM_scores_w <- pivot_wider(
  data = lhf_st2_GLMM_scores,
  id_cols = c(rCRS_pos,value),
  names_from = covariate, 
  values_from = log10_scores
) 
```

# Processing GLMM scores

## Correlations between variables

As I was not exactly sure which variables (especially the quarterly paleo ones)
are highly related predictors, I wanted to check which (if any) result in highly
correlated responses.

For now I have decided to keep all variables, but the number of predictors could
be slimmed down by removing on of two predictors that are highly correlated with
each other.

```{r env_correlations}
# calculate correlations between variables 
env_cor <- Hmisc::rcorr(
  as.matrix(
    lhf_gt_pc_st2_meta[,c(9,15:22,29,31:42)]
  )
)

# blank out half values to avoid repeats 
env_cor$r[lower.tri(env_cor$r)] <- NA

# transform matrix into a table 
env_cor <- reshape2::melt(
  env_cor$r,
  na.rm = TRUE
)

# round to 3 digits 
env_cor$value <- round(
  x = env_cor$value, 
  digits = 3
)
```

```{r plot_env_correlations}
ggplot2::ggplot(
  data = env_cor,
  ggplot2::aes(
    x = Var2,
    y = Var1,
    fill = value
  )
) +
  geom_tile(
    colour = "white"
  ) +
  geom_text(
    mapping = aes(
      label = value
    ),
    colour = "white",
    #size = 1.25 # if saving to pdf
    size = 2.5
  ) +
  xlab("")+
  ylab("")+
  labs(fill = "R-squared Correlation Coefficient") +
  scale_fill_gradient2(
    low = "navy",
    high = "maroon3",
    mid = "snow3",
    midpoint = 0,
    #limit = c(0.5,1),
    #space = "Lab",
    #name="Pearson\nCorrelation"
  ) +
  theme_light()+
  theme(
    axis.text.x = element_text(
      angle = 90,
      vjust = 0.5
    ), 
    legend.position = "bottom"
    # axis.title = element_blank(), 
    # legend.position = "none"
  ) #+
  #transparent_theme
```

```{r save_env_corr}
ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/figures/supplementary/lhf_env_corr_heatmap_08_2024.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 12, 
  height = 10
)
```

Some quick-fire takeaways here are:

-   endemic species and outbreaks by area to not correlate with climate
    variables

-   npp and lai correlate reasonably well with precipitation variables (both
    modern and paleo). (precip_yr_paleo is the strongest)

-   mean_T_yr_paleo is correlated with lots of modern and some paleoclimate
    variables

-   generally paleo and modern temperature data is highly correlated

```{r predictor_correlations}

# plot plant - related values
psych::pairs.panels(
  x = lhf_gt_pc_st2_meta[,c(9,15:22,29)] , 
  lm = TRUE, 
  stars = TRUE, 
  hist.col = "chartreuse4"
)

# cant fit col 10 for some reason?
psych::pairs.panels(
  x = lhf_gt_pc_st2_meta[,c(31:42)], 
  lm = TRUE, 
  stars = TRUE, 
  hist.col = "deepskyblue4"
)
# save these graphs ---- why is this not working?
#ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/figures/supplementary/lhf_env_corr_scatterplots_08_2024.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 12, 
  height = 10
)

```

## Defining significance thresholds

For now we are keeping a large number of variables. This is because:

1.  Latitude and precipitation are used in the first round of models.
2.  Maximum and Minimum temperature have been used in earlier studies.
3.  I don't have any strong prior reasoning about which of the paleo variables
    it would be smart to remove.

As we are assessing lots of test formulas we have to account for multiple
testing. As in the "core" models we use a significance threshold of 1%.

```{r GLMM_formatting}

# list the variables you want to keep 
var_to_keep <- c(
  "lat", "precip_yr",
  "tmp_max", "tmp_min", 
  "mean_T_yr_paleo", 
  "T_seasonality_paleo", "T_wetQ_paleo", "T_dryQ_paleo", 
  "mean_T_warmQ_paleo", "mean_T_coldQ_paleo", 
  "precip_yr_paleo", "precip_dryQ_paleo", "precip_coldQ_paleo",
  "npp_paleo",  "lai_paleo", "endemic_area",
  "outbreaks_area"
)

# only keep specified variables (currently most of them)
lhf_st2_GLMM_scores_f <- lhf_st2_GLMM_scores %>%
  filter(covariate %in% var_to_keep)

# this determines the significance threshold: 
alpha <- 0.01
# count the number of SNPs tested (should be all those that passed dispersion filters in the core tests)
n_snps_st2 <- length(unique(lhf_st2_GLMM_scores$rCRS_pos))
n_snps_st2
# calculate the number of test formulas conducted
n_tests <- length(unique(lhf_st2_GLMM_scores_f$covariate))
n_tests
# calculate the bonferroni corrected threshold
bon_threshold_st2 <- alpha/(n_snps_st2*n_tests)
log10(bon_threshold_st2)
```

## Merging with position data

As with the core models, we can add in information on where in mt genome the
significant hits arise.

```{r join_mt_loci}
# combine with position data 
lhf_st2_GLMM_scores_f <- left_join(
  lhf_st2_GLMM_scores_f, 
  mt_loci_pos, 
  by = join_by(
    rCRS_pos >= Starting, 
    rCRS_pos <= Ending
  )
)

# order classifications 
lhf_st2_GLMM_scores_f$classification <- factor(
  x = lhf_st2_GLMM_scores_f$classification, 
  levels = mt_classification_levels
)

# order loci positions
lhf_st2_GLMM_scores_f$Map.Locus <- factor(
  x = lhf_st2_GLMM_scores_f$Map.Locus, 
  levels = c(
    "MT-ATT", "MT-CR", # Attachment site and control region
    "MT-ND1", "MT-ND2", "MT-ND3", "MT-ND4", "MT-ND5", "MT-ND6",
    "MT-CYB",
    "MT-CO1","MT-CO2", "MT-CO3", 
    "MT-ATP6", "ATP8",
    "MT-RNR1", "MT-RNR2", 
    "MT-TT", "MT-TG", "MT-TR", "MT-TH" 
  )
)

```

## Summary Metrics

```{r format_sig_scores}

# Calculate the number of SNPs for which each covariate is significant
lhf_st2_GLMM_N <- lhf_st2_GLMM_scores_f %>%
  filter(`Pr(>Chisq)` <= bon_threshold_st2) %>% # bonferroni corrected pvalue
  group_by(covariate) %>%
  reframe( 
    N = n()
  ) %>%
  distinct()

# order the levels 
lhf_st2_GLMM_N$covariate <- factor(
  x = lhf_st2_GLMM_N$covariate, 
  levels = var_to_keep
)

# create a table with the most significant covariates for each SNP
lhf_st2_GLMM_min <- lhf_st2_GLMM_scores_f %>%
  filter(`Pr(>Chisq)` <= bon_threshold_st2) %>%
  #filter(!covariate %in% c("lat")) %>%
  group_by(rCRS_pos) %>%
  slice_min(log10_scores) %>%
  select(
    rCRS_pos, logLik, `Pr(>Chisq)`,
    covariate, value, log10_scores,
    Map.Locus, classification, Starting, Ending, length, snp_pos
  ) %>%
  distinct()

#feather::write_feather(
  x = lhf_st2_GLMM_min, 
  path = "~/Documents/data/lhf_d/feather/lhf_st2_GLMM_min_noLAT_08_2024.feather"
)

lhf_st2_GLMM_min <- feather::read_feather(
   path = "~/Documents/data/lhf_d/feather/lhf_st2_GLMM_min_noLAT_08_2024.feather"
)

# count the number of times a covariate is the strongest hit: 
lhf_st2_GLMM_min_N <- lhf_st2_GLMM_min %>%
  group_by(covariate) %>%
  reframe(
    N = n()
  ) %>%
  distinct 
  
# order these levels 
lhf_st2_GLMM_min_N$covariate <- factor(
  x = lhf_st2_GLMM_min_N$covariate, 
  levels = var_to_keep
)

lhf_st2_GLMM_summaries <- list(
  #lhf_st2_GLMM_N #,
  lhf_st2_GLMM_min_N
  )

```

```{r GLMM_summary_plot}

to_plot <- c(
  "N"
  #, "N"
  )


for(i in seq_along(lhf_st2_GLMM_summaries)) {

#for(i in 2) { 
  
  table <- lhf_st2_GLMM_summaries[[i]]
  
  print(
    ggplot2::ggplot(
      data = table, 
      mapping = ggplot2::aes(
        x = covariate, 
        y = .data[[to_plot[i]]], 
        fill = covariate
      )
    ) +
      geom_col(
        position = position_dodge2(0.2)
      ) +
      scale_fill_manual(
        values = env_var_palette
      ) +
      geom_text(
        mapping = aes(
          label = N
        ), 
        size = 12,
        nudge_y = 2
      ) +
      #facet_grid(
      #  rows = vars(classification)
      #) +
      theme_minimal(
      ) +
      ggplot2::theme(
        axis.text.x = element_text(
          angle = 90,
          vjust = 0,
          hjust = 0,
          size = 20
        ), 
        axis.title.y = element_text(
         size = 25
        ),
        legend.position = "none"
      )
  )
}
```

```{r save_paleo_hits}
#ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/figures/stage2_plots/lhf_st2_GLMM_N_mins_noLAT_08_2024_transparent.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 9
)
# repeat for all desired plots
```

To check if the same SNPs are detected in this analysis as in the core SNPs...

```{r check_overlap_snps}
# combine core and stage 2 results 
combined_st1_st2_GLMs <- full_join(
  x = core_GLM_min_null, 
  y = lhf_st2_GLMM_min %>%
    select(
      rCRS_pos, covariate
    ) %>%
    distinct(), 
  by = "rCRS_pos"
)

st2_hits <- c(unique(lhf_st2_GLMM_min$rCRS_pos))

# select the positions where there is no significant stage 2 hit
combined_st1_st2_GLMs %>%
  filter(is.na(covariate)) %>%
  select(rCRS_pos) %>%
  distinct()
```

This shows that there are 5 SNPs (200, 5460, 6455, 8701, 9947) which are not
detected as being significant in the second stage of modelling. This could be as
the Bonferroni corrected threshold is higher (as there are many more tests) or
that the interact between latitude and precipitation is specifically important
in the core hits.

```{r all_minSNPs_st2 }

lhf_st2_GLMM_min_allSNPs <- lhf_st2_GLMM_scores_f %>%
  #filter(`Pr(>Chisq)` <= bon_threshold_st2) %>%
  #filter(!covariate %in% c("lat")) %>%
  group_by(rCRS_pos) %>%
  slice_min(log10_scores) %>%
  select(
    rCRS_pos, logLik, `Pr(>Chisq)`,
    covariate, value, log10_scores,
    Map.Locus, classification, Starting, Ending, length, snp_pos
  ) %>%
  distinct()
```

## Manhattan Plot

```{r st2_GLMM_manhattan, warning=FALSE}

ggplot(
  data = lhf_st2_GLMM_scores_f, 
  #data = lhf_st2_GLMM_min_allSNPs,  # see above
  mapping = aes(
    y = log10_scores, 
    x = rCRS_pos
  )
  ) + 
  geom_point(
    mapping = aes(
      colour = covariate
    ), 
    size = 4, 
    #show.legend = FALSE
  ) + 
  ggplot2::geom_line(
    y = -1*log10(bon_threshold_st2), 
    colour = "black", 
    linewidth = 1
  ) +
  ggplot2::scale_colour_manual(
    values = c(
      mtDNA_palette, 
      env_var_palette
    )
  ) +
  ggplot2::scale_x_continuous(
    breaks = seq(0,17000, 1000)
  ) +
  ylim(
    values = c(1, -20)
  ) + 
  ggplot2::ylab(
    "Logged P-value"
  ) +
  geom_segment(
    data = mt_loci_pos,
    ggplot2::aes(
      x = Starting, 
      xend = Ending,
      y = 0.5, 
      yend = 0.5, 
      col = classification
    ),
    linewidth = 4, 
    alpha = 0.8, 
    position = ggplot2::position_jitter(
      height = 0.1
    )
  ) + 
  theme_minimal()+
  theme(
    legend.position = "top", 
    axis.line = ggplot2::element_line(
      linewidth = 1, 
      colour = "black"
    ), 
    plot.background = ggplot2::element_rect(
      fill = "snow"
    ), 
    panel.grid = ggplot2::element_line(
      colour = "snow", 
      linetype = "dotdash"
    ),
    panel.grid.major.x = ggplot2::element_line(
      colour = "snow4", 
      linetype = "dashed"
    ), 
    legend.background = ggplot2::element_rect(
      fill = "snow"
    )
  )

```

```{r save_st2_manhattan}
ggplot2::ggsave(
  filename = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/figures/stage2_plots/lhf_st2_allSNPs_manhattan_08_2024_transparent.png",
  plot = last_plot(),
  bg = "transparent", 
  width = 11, 
  height = 9
)
```

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

## Adding in Known Effects

Using the data from the MITOMAP database (see alternate Rmd for import details.)

```{r add_vep}
# combine with the Variant Effect Predictors 
lhf_st2_GLMM_min_vep <- left_join(
  x = lhf_st2_GLMM_min, 
  y = vep, 
  by = join_by(
    rCRS_pos == pos # note: here the VEP data uses the VCF/alignment positions, not the rCRS
  )
)
```

```{r}
ggplot2::ggplot(
  data = lhf_st2_GLMM_min_vep, 
  mapping = aes(
    x = as.factor(rCRS_pos), 
    y = Map.Locus, 
    colour = Consequence
  )
) +
  geom_point()
  geom_text(
    mapping = aes(
      label = rCRS_pos
    ),
    size = 4
  ) 

```

```{r save_GLM_vep}
openxlsx::write.xlsx(
  #x = lhf_st2_GLMM_min_vep, 
  file = "/Users/finleythomas/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Results/lhf/lhf_st2_GLMM_min_vep_08_2024.xlsx"
)
```

# \-\-\-\-\--

```{r}

# merging the two plots together 
interact_interest_chi_combo <- left_join(
  x = interact_interest_chi_sq, 
  y = interact_interest_chi, 
  by = c(
    "snp_pos",
    "test_formulas[i]"
  )
)

interact_interest_chi_combo <- interact_interest_chi_combo %>%
  distinct() %>% 
  #filter(!is.na(`Pr(>Chisq).y`)) %>%
  filter(!is.na(`Pr(>Chisq).x`)) %>% # remove rows with no pval (null models)
  mutate(
    log_interact_pval = signif(
      log10(
        `Pr(>Chisq).y` # log 10 the pvals showing if there is a significant difference between additive and interactive models
      )
    )
  ) %>%
  mutate(
    log_interact_pval = round(
      log_interact_pval,  # round these p values
      3
    )
  )

length(interest_snps_precip_yr)

interact_interest_chi_combo$log_interact_pval[interact_interest_chi_combo$log_interact_pval > log10(
   (0.05/48*2)
  )] <- NA  # remove the labels for any poitions that do not pass the threshold

interact_interest_chi_combo <- left_join(
  x = interact_interest_chi_combo, 
  y = rCRS, 
  by = join_by("snp_pos" == "aln_pos")
)
```

## Plotting allele frequencies

```{r import_allele_freq}

allele_freq <- feather::read_feather(
  path = "~/Documents/data/lhf_d/lhf_country_allele_freq_maf0.005.feather"
)

allele_freq$pos <- as.numeric(allele_freq$pos)

allele_freq <- left_join(
  x = allele_freq, 
  y = rCRS, 
  by = join_by(pos == aln_pos)
)

```

```{r plot_focal_AF}

focal_snps <- unique(lhf_st2_GLMM_scores_f$snp_pos[lhf_st2_GLMM_scores_f$log10_scores <= log10(bon_threshold_st2)])

focal_snps <- c(2706,10238,152, 8701,10398,10034,15924, 15218)
focal_snps <- sort(focal_snps)

for (i in focal_snps){
  print(i)
  
  allele_freq_select <- allele_freq %>%
    filter(rCRS_pos == i)
  
  p <- ggplot(
  data = allele_freq_select, 
  mapping = ggplot2::aes(
    x =  reorder(x = ISO2, +a2_freq), # plot the bars in value order
    y = a2_freq, # value to plot
    colour = continent
  )
) + 
  ggplot2::geom_point(
    #stat = "identity"
  ) +
  ggplot2::scale_colour_manual(
    values = c(
      "deepskyblue4", "firebrick4", "darkorchid3", "chartreuse4", "turquoise",
  "chartreuse3"
    )
  ) +
  ggplot2::theme(
     axis.text.x = ggplot2::element_text(
       angle = 90,
       vjust = 0.5,
       hjust = 0.5,
       size = 3
       )
  ) + 
    ggtitle(
      paste0(
       "Position: ",
        unique(allele_freq_select$rCRS_pos)
      )
  ) +
  xlab("Country"
  ) + 
  ylab(
  "Allele Frequency"
  )
  
  print(p)
  
}


allele_freq_focal <- allele_freq %>%
  filter(
    rCRS_pos %in% focal_snps
  )

ggplot2::ggplot(
  data = allele_freq_focal, 
  mapping = ggplot2::aes(
    x =  reorder(x = ISO2, +a2_freq), # plot the bars in value order
    y = a2_freq, # value to plot
    colour = continent
  )
) + 
  ggplot2::geom_point(
    #stat = "identity"
  ) +
  ggplot2::scale_colour_manual(
    values = c(
      "deepskyblue4", "firebrick4", "darkorchid3", "chartreuse4", "turquoise",
  "chartreuse3"
    )
  ) +
  ggplot2::theme(
     axis.text.x = ggplot2::element_text(
       angle = 90,
       vjust = 0.5,
       hjust = 0.5,
       size = 5
       )
) +
#ggplot2::ylim(c(
#    min(allele_freq_select$a1_freq)-0.05, 1 # set the axis to be more precise
#  )
#) + 
#  paste0(
#    "Position: ",
#    unique(allele_freq_select$pos)
#  )
#) +
ggplot2::xlab("Country"
) + 
ggplot2::ylab(
  "Allele Frequency"
) +
  facet_wrap(
    ~(rCRS_pos)
  )
```

```{r}
focal_snps <- unique(precip_interest_chi_sq$rCRS_pos)
focal_snps <- sort(focal_snps)


for (i in focal_snps){
  print(i)
  
  allele_freq_select <- allele_freq %>%
    filter(rCRS_pos == i)
  
  p <- ggplot(
  data = allele_freq_select, 
  mapping = ggplot2::aes(
    x =  lat, # plot the bars in value order
    y = a2_freq, # value to plot
    colour = continent
  )
) + 
  ggplot2::geom_point(
    #stat = "identity"
  ) +
  ggplot2::scale_colour_manual(
    values = c(
      "deepskyblue4", "firebrick4", "darkorchid3", "chartreuse4", "turquoise",
  "chartreuse3"
    )
  ) +
  ggplot2::theme(
     axis.text.x = ggplot2::element_text(
       angle = 90,
       vjust = 0.5,
       hjust = 0.5,
       size = 3
       )
  ) + 
    ggtitle(
      paste0(
       "Position: ",
        unique(allele_freq_select$rCRS_pos)
      )
  ) +
  xlab("Country"
  ) + 
  ylab(
  "Allele Frequency"
  )
  
  print(p)
  
}

```
